from fastapi import FastAPI, File, UploadFile, HTTPException, Body
from fastapi.responses import JSONResponse
from PIL import Image
import io
from pydantic import BaseModel, Field
import base64



########################
from typing import Optional
import numpy as np
import torch
from PIL import Image
import io


import base64, os
from utils import check_ocr_box, get_yolo_model, get_caption_model_processor, get_som_labeled_img
import torch
from PIL import Image

yolo_model_orig = get_yolo_model(model_path='weights/icon_detect/best.pt')
yolo_model = get_yolo_model(model_path='weights/icon_detect/yolo11x.pt')
caption_model_processor = get_caption_model_processor(model_name="florence2", model_name_or_path="weights/icon_caption_florence")
# caption_model_processor = get_caption_model_processor(model_name="blip2", model_name_or_path="weights/icon_caption_blip2")



MARKDOWN = """
# OmniParser for Pure Vision Based General GUI Agent ğŸ”¥
<div>
    <a href="https://arxiv.org/pdf/2408.00203">
        <img src="https://img.shields.io/badge/arXiv-2408.00203-b31b1b.svg" alt="Arxiv" style="display:inline-block;">
    </a>
</div>

OmniParser is a screen parsing tool to convert general GUI screen to structured elements. 
"""

DEVICE = torch.device('cuda')

# @spaces.GPU
# @torch.inference_mode()
# @torch.autocast(device_type="cuda", dtype=torch.bfloat16)
def process(
    image_input,
    box_threshold,
    iou_threshold,
    use_paddleocr,
    imgsz
) -> Optional[Image.Image]:

    image_save_path = 'imgs/saved_image_demo.png'
    image_input.save(image_save_path)
    image = Image.open(image_save_path)
    box_overlay_ratio = image.size[0] / 3200
    draw_bbox_config = {
        'text_scale': 0.8 * box_overlay_ratio,
        'text_thickness': max(int(2 * box_overlay_ratio), 1),
        'text_padding': max(int(3 * box_overlay_ratio), 1),
        'thickness': max(int(3 * box_overlay_ratio), 1),
    }
    # import pdb; pdb.set_trace()

    ocr_bbox_rslt, is_goal_filtered = check_ocr_box(image_save_path, display_img = False, output_bb_format='xyxy', goal_filtering=None, easyocr_args={'paragraph': False, 'text_threshold':0.9}, use_paddleocr=use_paddleocr)
    text, ocr_bbox = ocr_bbox_rslt
    
    # print('prompt:', prompt)
    dino_labled_img_orig, label_coordinates_orig, parsed_content_list_orig = get_som_labeled_img(image_save_path, yolo_model_orig, BOX_TRESHOLD = box_threshold, output_coord_in_ratio=True, ocr_bbox=ocr_bbox,draw_bbox_config=draw_bbox_config, caption_model_processor=caption_model_processor, ocr_text=text,iou_threshold=iou_threshold, imgsz=imgsz)  
    image_orig = Image.open(io.BytesIO(base64.b64decode(dino_labled_img_orig)))
    print('finish processing')
    #parsed_content_list_orig = '\n'.join(parsed_content_list_orig)

    # print('prompt:', prompt)
    
    # dino_labled_img, label_coordinates, parsed_content_list = get_som_labeled_img(image_save_path, yolo_model, BOX_TRESHOLD = box_threshold, output_coord_in_ratio=True, ocr_bbox=ocr_bbox,draw_bbox_config=draw_bbox_config, caption_model_processor=caption_model_processor, ocr_text=text,iou_threshold=iou_threshold, imgsz=imgsz)  
    # image = Image.open(io.BytesIO(base64.b64decode(dino_labled_img)))
    # print('finish processing')
    
    #parsed_content_list = '\n'.join(parsed_content_list)
    
    image = image_orig
    label_coordinates = label_coordinates_orig
    parsed_content_list = parsed_content_list_orig
    
    return image, label_coordinates, parsed_content_list

########################




app = FastAPI(
    title="OmniParser API",
    description="ä½¿ç”¨ FastAPI æä¾›çš„ OmniParser RESTful API æœåŠ¡",
    version="1.0.0"
)

class ResponseItem(BaseModel):
    item_id: str = Field(..., description="æ•°å€¼ç±»å‹ï¼Œè¡¨ç¤ºè§£ææ¡†åºå·ï¼Œä»0å¼€å§‹")
    item_type: str = Field(..., description="å­—ç¬¦ä¸²æšä¸¾ï¼Œè¡¨ç¤ºè§£ææ¡†ç±»å‹ï¼Œ å–å€¼èŒƒå›´ä¸º'text'æˆ–'icon'")
    info: str = Field(..., description="ä¿¡æ¯ï¼Œè¡¨ç¤ºè§£ææ¡†å†…çš„ä¿¡æ¯ï¼Œ ç±»å‹ä¸ºå­—ç¬¦ä¸²")
    cxcywh: list[int] = Field(..., description="åŒ…å«4ä¸ªæ•°å€¼å‹å…ƒç´ çš„listï¼Œæ ‡è¯†ä¸€ä¸ªbox, å››ä¸ªæ•°å€¼åˆ†åˆ«è¡¨ç¤ºboxçš„ä¸­å¿ƒåæ ‡xyå’Œboxçš„å®½é«˜wh")

class ProcessImageResponse(BaseModel):
    """
    è§£æå›¾åƒçš„å“åº”
    """
    image_with_bbox: str = Field(..., description="åŒ…å«è¾¹ç•Œæ¡†çš„å›¾åƒï¼Œç±»å‹ä¸ºbase64ç¼–ç çš„å­—ç¬¦ä¸²")
    parsed_content_list: list[ResponseItem] = Field(
        ...,
        description="è§£æåçš„å†…å®¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºResponseItemç±»å‹"
    )



@app.post("/process-image/", response_model=ProcessImageResponse)
async def process_image(
    image_base64: str = Body(..., description="ç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºå›¾åƒçš„base64ç¼–ç æ•°æ®"),
    box_threshold: float = Body(0.05, description="ç±»å‹ä¸ºæµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºç”¨äºè¿‡æ»¤ä½ç½®ä¿¡åº¦è¾¹ç•Œæ¡†çš„é˜ˆå€¼"),
    iou_threshold: float = Body(0.1, description="ç±»å‹ä¸ºæµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºç”¨äºè¿‡æ»¤é‡å è¾¹ç•Œæ¡†çš„é˜ˆå€¼"),
    use_paddleocr: bool = Body(True, description="ç±»å‹ä¸ºå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦ä½¿ç”¨PaddleOCRè¿›è¡ŒOCRè¯†åˆ«"),
    imgsz: int = Body(640, description="ç±»å‹ä¸ºæ•´æ•°ï¼Œè¡¨ç¤ºç”¨äºicon detectionçš„å›¾åƒå°ºå¯¸")
):
    try:
        # è§£ç  base64 å›¾åƒæ•°æ®
        image_data = base64.b64decode(image_base64)
        image = Image.open(io.BytesIO(image_data))

        # è°ƒç”¨ process å‡½æ•°
        processed_image, label_coordinates, parsed_content_list = process(
            image_input=image,
            box_threshold=box_threshold,
            iou_threshold=iou_threshold,
            use_paddleocr=use_paddleocr,
            imgsz=imgsz
        )
        '''
        label_coordinates:æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œkeyæ˜¯idxï¼Œå–å€¼"0", "1", "2", ... "n" è¡¨ç¤º parsed_content_listçš„ä¸‹æ ‡ã€‚
        valueæ˜¯listï¼ŒåŒ…å«4ä¸ªæ•°å€¼å‹å…ƒç´ ï¼Œåˆ†åˆ«ä¸ºå·¦ä¸Šx,yå’Œå³ä¸‹x,y.æ³¨æ„ï¼Œx,yçš„å–å€¼èŒƒå›´ä¸º[0,1]ï¼Œåˆ†åˆ«è¡¨ç¤ºå›¾åƒå®½åº¦å’Œé«˜åº¦çš„æ¯”ä¾‹ä½ç½®ã€‚
        parsed_content_listï¼šæ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºè§£æåçš„å†…å®¹ã€‚
        æœ‰ä¸¤ç§å‰ç¼€å¼€å¤´ï¼š
        1. "Text Box ID"ï¼Œ è¡¨ç¤ºæ–‡æœ¬æ¡†
        2. "Icon Box ID"ï¼Œ è¡¨ç¤ºå›¾æ ‡æ¡†
        '''
        # æ„é€  parsed_content_list
        parsed_content_list_response = []
        for idx, content in enumerate(parsed_content_list):
            if content.startswith("Text Box ID"):
                item_type = "text"
            elif content.startswith("Icon Box ID"):
                item_type = "icon"
            else:
                continue

            cxcywh = label_coordinates[str(idx)]
            # æå–ä¿¡æ¯
            # è·å–å›¾åƒçš„å®½åº¦å’Œé«˜åº¦
            image_width, image_height = image.size

            # è®¡ç®—åƒç´ åæ ‡
            center_x = int(cxcywh[0] * image_width)
            center_y = int(cxcywh[1] * image_height)
            width = int(cxcywh[2] * image_width)
            height = int(cxcywh[3] * image_height)

            # æ›´æ–°cxcywhä¸ºåƒç´ åæ ‡
            cxcywh = [center_x, center_y, width, height]
            
            info = content.split(f"Box ID {idx}: ")[1] if ": " in content else content

            parsed_content_list_response.append({
                "item_id": str(idx),
                "item_type": item_type,
                "info": info,
                "cxcywh": cxcywh
            })


        # å°†å›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç çš„å­—ç¬¦ä¸²
        buffered = io.BytesIO()
        processed_image.save(buffered, format="PNG")
        image_with_bbox_base64 = base64.b64encode(buffered.getvalue()).decode()

        # æ„é€  ProcessImageResponse
        response = ProcessImageResponse(
            image_with_bbox=image_with_bbox_base64,
            parsed_content_list=parsed_content_list_response
        )

        return JSONResponse(content=response.model_dump())

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# å¯åŠ¨å‘½ä»¤: uvicorn fastapi_server:app --reload --port 8899